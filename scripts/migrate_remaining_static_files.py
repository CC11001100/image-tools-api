#!/usr/bin/env python3
"""
è¿ç§»å‰©ä½™çš„é™æ€æ–‡ä»¶åˆ°OSS
åŒ…æ‹¬screenshotsã€public/generatedã€æµ‹è¯•æ–‡ä»¶ç­‰
"""

import sys
import os
import json
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from app.services.oss_client import oss_client


class RemainingStaticFilesMigration:
    """å‰©ä½™é™æ€æ–‡ä»¶è¿ç§»æœåŠ¡"""
    
    def __init__(self):
        self.oss_client = oss_client
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp', '.svg', '.ico'}
        
        # éœ€è¦å¤„ç†çš„æ–‡ä»¶å’Œç›®å½•
        self.target_files = [
            "public/test_image.jpg",
            "watermark_test_output.jpg",
        ]
        
        self.target_directories = [
            "public/generated",
            "screenshots",
        ]
        
        # æ’é™¤çš„ç›®å½•å’Œæ–‡ä»¶
        self.exclude_patterns = {
            'backup',
            'node_modules', 
            '__pycache__', 
            '.git',
            'build',
            'venv',
            'test-results',  # Playwrightæµ‹è¯•ç»“æœ
            'debug-api-docs.png'  # è°ƒè¯•æ–‡ä»¶
        }
        
    def scan_remaining_static_files(self) -> List[Dict[str, str]]:
        """
        æ‰«æå‰©ä½™çš„é™æ€æ–‡ä»¶
        
        Returns:
            åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        """
        files = []
        
        # æ‰«ææŒ‡å®šçš„å•ä¸ªæ–‡ä»¶
        for file_path in self.target_files:
            full_path = project_root / file_path
            if full_path.exists() and full_path.is_file():
                files.append(self._create_file_info(full_path))
        
        # æ‰«ææŒ‡å®šçš„ç›®å½•
        for dir_path in self.target_directories:
            full_dir = project_root / dir_path
            if full_dir.exists() and full_dir.is_dir():
                files.extend(self._scan_directory(full_dir))
        
        print(f"æ‰«æåˆ° {len(files)} ä¸ªå‰©ä½™é™æ€æ–‡ä»¶")
        return files
    
    def _scan_directory(self, directory: Path) -> List[Dict[str, str]]:
        """
        é€’å½’æ‰«æç›®å½•
        
        Args:
            directory: è¦æ‰«æçš„ç›®å½•
            
        Returns:
            æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        files = []
        
        for item in directory.rglob("*"):
            # è·³è¿‡æ’é™¤çš„ç›®å½•å’Œæ–‡ä»¶
            if any(exclude in item.parts for exclude in self.exclude_patterns):
                continue
                
            if item.is_file() and item.suffix.lower() in self.image_extensions:
                files.append(self._create_file_info(item))
        
        return files
    
    def _create_file_info(self, file_path: Path) -> Dict[str, str]:
        """
        åˆ›å»ºæ–‡ä»¶ä¿¡æ¯å­—å…¸
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶ä¿¡æ¯å­—å…¸
        """
        # è®¡ç®—ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        relative_to_project = file_path.relative_to(project_root)
        
        # æ„å»ºOSSå¯¹è±¡é”®
        # å¯¹äºä¸åŒç±»å‹çš„æ–‡ä»¶ä½¿ç”¨ä¸åŒçš„å‰ç¼€
        if "screenshots" in str(file_path):
            object_key = f"screenshots/{file_path.name}"
        elif "generated" in str(file_path):
            object_key = f"generated/{file_path.name}"
        elif "test" in file_path.name.lower():
            object_key = f"test/{file_path.name}"
        else:
            object_key = f"misc/{file_path.name}"
        
        return {
            "local_path": str(file_path),
            "relative_path": str(relative_to_project),
            "object_key": object_key,
            "size": file_path.stat().st_size,
            "name": file_path.name,
            "category": self._get_file_category(file_path)
        }
    
    def _get_file_category(self, file_path: Path) -> str:
        """è·å–æ–‡ä»¶åˆ†ç±»"""
        if "screenshots" in str(file_path):
            return "screenshots"
        elif "generated" in str(file_path):
            return "generated"
        elif "test" in file_path.name.lower():
            return "test"
        else:
            return "misc"
    
    def upload_files_to_oss(self, files: List[Dict[str, str]]) -> Tuple[List[Dict], List[Dict]]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°OSS
        
        Args:
            files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            (æˆåŠŸåˆ—è¡¨, å¤±è´¥åˆ—è¡¨) çš„å…ƒç»„
        """
        success_files = []
        failed_files = []
        
        print(f"å¼€å§‹ä¸Šä¼  {len(files)} ä¸ªé™æ€æ–‡ä»¶åˆ°OSS...")
        
        for i, file_info in enumerate(files, 1):
            try:
                print(f"[{i}/{len(files)}] ä¸Šä¼ : {file_info['relative_path']}")
                
                # ç¡®å®šMIMEç±»å‹
                content_type = self._get_content_type(file_info["name"])
                
                # ä¸Šä¼ åˆ°OSS
                url = self.oss_client.upload_file(
                    file_path=file_info["local_path"],
                    object_key=file_info["object_key"],
                    content_type=content_type
                )
                
                if url:
                    file_info["oss_url"] = url
                    success_files.append(file_info)
                    print(f"  âœ“ æˆåŠŸ: {url}")
                else:
                    failed_files.append(file_info)
                    print(f"  âœ— å¤±è´¥")
                    
            except Exception as e:
                file_info["error"] = str(e)
                failed_files.append(file_info)
                print(f"  âœ— å¼‚å¸¸: {str(e)}")
        
        return success_files, failed_files
    
    def _get_content_type(self, filename: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹"""
        ext = Path(filename).suffix.lower()
        content_types = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.webp': 'image/webp',
            '.bmp': 'image/bmp',
            '.svg': 'image/svg+xml',
            '.ico': 'image/x-icon'
        }
        return content_types.get(ext, 'image/jpeg')
    
    def update_references(self, success_files: List[Dict]) -> List[str]:
        """
        æ›´æ–°ä»£ç ä¸­çš„æ–‡ä»¶å¼•ç”¨
        
        Args:
            success_files: æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            æ›´æ–°çš„æ–‡ä»¶åˆ—è¡¨
        """
        updated_files = []
        
        # åˆ›å»ºæœ¬åœ°è·¯å¾„åˆ°OSS URLçš„æ˜ å°„
        path_mapping = {}
        for file_info in success_files:
            local_path = file_info["relative_path"]
            oss_url = file_info["oss_url"]
            path_mapping[local_path] = oss_url
            
            # ä¹Ÿæ·»åŠ ç»å¯¹è·¯å¾„æ˜ å°„
            if local_path.startswith("public/"):
                web_path = "/" + local_path[7:]  # ç§»é™¤ "public/" å‰ç¼€
                path_mapping[web_path] = oss_url
        
        # æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„æ–‡ä»¶
        search_patterns = [
            "frontend/src/**/*.ts",
            "frontend/src/**/*.tsx", 
            "frontend/src/**/*.js",
            "frontend/src/**/*.jsx",
            "*.md",
            "*.py",
            "*.html"
        ]
        
        files_to_check = []
        for pattern in search_patterns:
            files_to_check.extend(project_root.glob(pattern))
        
        # æ›´æ–°æ–‡ä»¶å¼•ç”¨
        for file_path in files_to_check:
            if self._update_file_references(file_path, path_mapping):
                updated_files.append(str(file_path.relative_to(project_root)))
        
        return updated_files
    
    def _update_file_references(self, file_path: Path, path_mapping: Dict[str, str]) -> bool:
        """
        æ›´æ–°å•ä¸ªæ–‡ä»¶ä¸­çš„å¼•ç”¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            path_mapping: è·¯å¾„æ˜ å°„å­—å…¸
            
        Returns:
            æ˜¯å¦æœ‰æ›´æ–°
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # æ›¿æ¢æ‰€æœ‰æ˜ å°„çš„è·¯å¾„
            for local_path, oss_url in path_mapping.items():
                # å¤„ç†ä¸åŒçš„å¼•ç”¨æ ¼å¼
                patterns = [
                    rf'["\']({re.escape(local_path)})["\']',
                    rf'["\']\./{re.escape(local_path)}["\']',
                    rf'["\']\.\./{re.escape(local_path)}["\']',
                ]
                
                for pattern in patterns:
                    content = re.sub(pattern, f'"{oss_url}"', content)
            
            # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… å·²æ›´æ–°å¼•ç”¨: {file_path.relative_to(project_root)}")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ æ›´æ–°å¼•ç”¨å¤±è´¥: {file_path} - {str(e)}")
            return False
    
    def cleanup_local_files(self, success_files: List[Dict], backup: bool = True) -> bool:
        """
        æ¸…ç†æœ¬åœ°æ–‡ä»¶
        
        Args:
            success_files: æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
            backup: æ˜¯å¦å¤‡ä»½åˆ°backupç›®å½•
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if backup:
            backup_dir = project_root / "backup" / "remaining-static-files"
            backup_dir.mkdir(parents=True, exist_ok=True)
        
        for file_info in success_files:
            try:
                local_path = Path(file_info["local_path"])
                
                if backup:
                    # å¤‡ä»½æ–‡ä»¶
                    backup_file = backup_dir / file_info["name"]
                    backup_file.write_bytes(local_path.read_bytes())
                    print(f"ğŸ“¦ å·²å¤‡ä»½: {backup_file}")
                
                # åˆ é™¤åŸæ–‡ä»¶
                local_path.unlink()
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤: {local_path}")
                
            except Exception as e:
                print(f"âŒ æ¸…ç†æ–‡ä»¶å¤±è´¥: {file_info['local_path']} - {str(e)}")
                return False
        
        return True
    
    def generate_report(self, success_files: List[Dict], failed_files: List[Dict], 
                       updated_files: List[str]) -> Dict:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        return {
            "timestamp": str(Path(__file__).stat().st_mtime),
            "total_files": len(success_files) + len(failed_files),
            "success_count": len(success_files),
            "failed_count": len(failed_files),
            "updated_references": len(updated_files),
            "success_files": success_files,
            "failed_files": failed_files,
            "updated_files": updated_files,
            "total_size": sum(f["size"] for f in success_files)
        }


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("å‰©ä½™é™æ€æ–‡ä»¶è¿ç§»åˆ°é˜¿é‡Œäº‘OSS")
    print("=" * 60)
    
    migration = RemainingStaticFilesMigration()
    
    # 1. æ‰«æå‰©ä½™é™æ€æ–‡ä»¶
    print("\n1. æ‰«æå‰©ä½™é™æ€æ–‡ä»¶...")
    files = migration.scan_remaining_static_files()
    
    if not files:
        print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„é™æ€æ–‡ä»¶")
        return
    
    # æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡
    total_size = sum(f["size"] for f in files)
    print(f"æ‰¾åˆ° {len(files)} ä¸ªé™æ€æ–‡ä»¶ï¼Œæ€»å¤§å°: {total_size / (1024*1024):.2f}MB")
    
    # æŒ‰åˆ†ç±»æ˜¾ç¤º
    by_category = {}
    for f in files:
        category = f["category"]
        if category not in by_category:
            by_category[category] = []
        by_category[category].append(f)
    
    for category, file_list in by_category.items():
        size = sum(f["size"] for f in file_list)
        print(f"  {category}: {len(file_list)} ä¸ªæ–‡ä»¶ ({size / (1024*1024):.2f}MB)")
    
    # 2. ä¸Šä¼ åˆ°OSS
    print("\n2. ä¸Šä¼ æ–‡ä»¶åˆ°OSS...")
    success_files, failed_files = migration.upload_files_to_oss(files)
    
    print(f"\nä¸Šä¼ ç»“æœ:")
    print(f"  æˆåŠŸ: {len(success_files)} ä¸ªæ–‡ä»¶")
    print(f"  å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶")
    
    if failed_files:
        print("\nå¤±è´¥çš„æ–‡ä»¶:")
        for f in failed_files:
            print(f"  - {f['relative_path']}: {f.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    # 3. æ›´æ–°å¼•ç”¨
    print("\n3. æ›´æ–°ä»£ç ä¸­çš„æ–‡ä»¶å¼•ç”¨...")
    updated_files = migration.update_references(success_files)
    print(f"æ›´æ–°äº† {len(updated_files)} ä¸ªæ–‡ä»¶ä¸­çš„å¼•ç”¨")
    
    # 4. ç”ŸæˆæŠ¥å‘Š
    report = migration.generate_report(success_files, failed_files, updated_files)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = project_root / "remaining_static_migration_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š è¿ç§»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # 5. è¯¢é—®æ˜¯å¦æ¸…ç†æœ¬åœ°æ–‡ä»¶
    if success_files:
        print(f"\næ˜¯å¦æ¸…ç†æœ¬åœ°æ–‡ä»¶? (y/N): ", end="")
        response = input().strip().lower()
        if response == 'y':
            print("\n5. æ¸…ç†æœ¬åœ°æ–‡ä»¶...")
            if migration.cleanup_local_files(success_files, backup=True):
                print("âœ… æœ¬åœ°æ–‡ä»¶æ¸…ç†å®Œæˆ")
            else:
                print("âŒ æœ¬åœ°æ–‡ä»¶æ¸…ç†å¤±è´¥")
    
    print("\n" + "=" * 60)
    print("å‰©ä½™é™æ€æ–‡ä»¶è¿ç§»å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
